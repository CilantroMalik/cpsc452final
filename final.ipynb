{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b620c-9456-41b4-9e88-f11d8090f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e57e8cfe-3031-4e8b-9f4a-0a8eac7ea6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, InMemoryDataset, Dataset\n",
    "from torch_geometric.nn import GATConv, GATv2Conv, DMoNPooling\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from plotnine import ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "308170d3-8192-4cd2-a7dc-16e32ff60105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "metacells = pd.read_csv(\"./oligo-SCZ-metacellExpr.csv\", index_col=0)\n",
    "metadata = pd.read_csv(\"./oligo-SCZ-meta.csv\", index_col=0)\n",
    "tom = pd.read_csv(\"./oligo-SCZ-tom.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3688d75-b0e4-4f0c-afc2-9c0976efa9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oligo#CON1_2             Control\n",
       "Oligo#CON10_5            Control\n",
       "Oligo#CON10_55           Control\n",
       "Oligo#CON10_105          Control\n",
       "Oligo#CON11_41           Control\n",
       "                       ...      \n",
       "Oligo#SZ15_10      Schizophrenia\n",
       "Oligo#SZ16_47      Schizophrenia\n",
       "Oligo#SZ16_97      Schizophrenia\n",
       "Oligo#SZ16_147     Schizophrenia\n",
       "Oligo#SZ18_1       Schizophrenia\n",
       "Name: disorder, Length: 100, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.iloc[1:5000:50,:][\"disorder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ffebb55c-3a75-4316-ad62-eef1a4a0c9f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2020705548.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m(1:100)\u001b[39m\n      ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fcf3c1a-3706-4ec2-bd91-c101d2f22c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 1.28492008, ..., 3.60950374, 1.82917698,\n",
       "       0.83603014], shape=(6679,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metacells.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80ce2079-8a74-4111-a1c1-052721ff72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "TOM_THRESHOLD = 0.025  # value below which we zero out the similarity that will be used as attention priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8734aa97-8f22-470f-82d9-b36b4a8dc813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6679/6679 [04:21<00:00, 25.57it/s] \n"
     ]
    }
   ],
   "source": [
    "# create graph dataset\n",
    "edges = []\n",
    "for i in tqdm(range(len(tom.columns))):\n",
    "    for j in range(i):\n",
    "        if tom.iloc[i,j] > TOM_THRESHOLD:\n",
    "            edges.extend([[i,j],[j,i]])\n",
    "edges = torch.tensor(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42d0beec-7d02-4117-96bd-57e339a06a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metacellsReduced = metacells.iloc[:,0:5000:50]\n",
    "metadataReduced = metadata.iloc[0:5000:50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3df5d3d7-e95b-4f52-b72d-8a094c40193d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "property 'num_classes' of 'GeneGraphDataset' object has no setter",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     34\u001b[39m             data = torch.load(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./graphData/processed/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.expr_mat.columns[idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-graph.pt\u001b[39m\u001b[33m\"\u001b[39m, weights_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     35\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m dataset = \u001b[43mGeneGraphDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./graphData\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43medges\u001b[49m\u001b[43m.\u001b[49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr_mat\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetacellsReduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadataReduced\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mGeneGraphDataset.__init__\u001b[39m\u001b[34m(self, root, edge_index, expr_mat, meta, transform, pre_transform)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mself\u001b[39m.num_graphs = expr_mat.shape[\u001b[32m1\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;28mself\u001b[39m.expr_mat = expr_mat\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_classes\u001b[49m = \u001b[32m2\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mself\u001b[39m.y = meta[\u001b[33m\"\u001b[39m\u001b[33mdisorder\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      8\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(root, transform, pre_transform)\n",
      "\u001b[31mAttributeError\u001b[39m: property 'num_classes' of 'GeneGraphDataset' object has no setter"
     ]
    }
   ],
   "source": [
    "class GeneGraphDataset(InMemoryDataset):\n",
    "    def __init__(self, root, edge_index, expr_mat, meta, transform=None, pre_transform=None):\n",
    "        self.edge_index = edge_index\n",
    "        self.num_graphs = expr_mat.shape[1]\n",
    "        self.expr_mat = expr_mat\n",
    "        self.num_classes = 2\n",
    "        self.y = meta[\"disorder\"]\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.load(\"./graphData/processed/combined.pt\")\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f\"./graphData/processed/{self.expr_mat.columns[i]}-graph.pt\" for i in range(self.num_graphs)]\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        for i in tqdm(range(self.num_graphs)):\n",
    "            node_features = torch.tensor(self.expr_mat.iloc[:,i].values)\n",
    "            data = Data(x=node_features, edge_index=self.edge_index)\n",
    "            data_list.append(data)\n",
    "            torch.save(data, f\"./graphData/processed/{self.expr_mat.columns[i]}-graph.pt\")\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), f\"./graphData/processed/combined.pt\")\n",
    "\n",
    "    def get(self, idx=None, sample=None):\n",
    "        if idx is None:\n",
    "            data = torch.load(f\"./graphData/processed/{sample}-graph.pt\", weights_only=False)\n",
    "        else:\n",
    "            data = torch.load(f\"./graphData/processed/{self.expr_mat.columns[idx]}-graph.pt\", weights_only=False)\n",
    "        return data\n",
    "\n",
    "\n",
    "dataset = GeneGraphDataset(root='./graphData', edge_index=edges.t().contiguous(), expr_mat=metacellsReduced, meta=metadataReduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "281c0507-60d4-4df5-9784-e9ff17702db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 13268.50it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for i in tqdm(range(100)):\n",
    "    dataset.append(Data(x=torch.tensor(metacellsReduced.iloc[:,i].values), edge_index=edges, y=metadataReduced[\"disorder\"].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "087ba992-e904-4591-a877-6666d2c7482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "97e58a07-9578-4459-bfdf-7f66396e9808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.num_features = 1\n",
    "        self.hidden_layers = 1\n",
    "        self.k1 = 512\n",
    "        self.k2 = 128\n",
    "        self.in_heads = 8\n",
    "        self.mid_heads = 2\n",
    "        self.out_heads = 1\n",
    "\n",
    "        self.conv1 = GATv2Conv(self.num_features, self.hidden_layers, heads=self.in_heads, dropout=0.4)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(self.hidden_layers * self.in_heads)\n",
    "        self.conv2 = GATv2Conv(self.hidden_layers*self.in_heads, self.hidden_layers, heads=self.mid_heads, dropout=0.4)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(self.hidden_layers * self.mid_heads)\n",
    "        self.conv3 = GATv2Conv(self.hidden_layers*self.mid_heads, self.hidden_layers, heads=self.out_heads, dropout=0.4)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(self.hidden_layers)\n",
    "\n",
    "        self.pool1 = DMoNPooling([self.hidden_layers, self.hidden_layers], k=self.k1, dropout=0.4)\n",
    "        self.pool2 = DMoNPooling([self.hidden_layers, self.hidden_layers], k=self.k2, dropout=0.4)\n",
    "\n",
    "        self.proj = torch.nn.Linear(self.hidden_layers, 1)\n",
    "\n",
    "        self.classifier = torch.nn.Linear(128, 2)\n",
    "\n",
    "    def _dense_adj(edge_index, alpha, batch):\n",
    "        alpha = alpha.mean(dim=1)\n",
    "        adj = to_dense_adj(edge_index, batch=batch, edge_attr=alpha).squeeze(0)\n",
    "        deg_inv = adj.sum(-1).clamp(min=1e-12).pow(-0.5)\n",
    "        return deg_inv.unsqueeze(1) * adj * deg_inv.unsqueeze(0)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, ei, batch = data.x, data.edge_index, data.batch\n",
    "        print(x)\n",
    "        print(ei)\n",
    "        print(batch)\n",
    "\n",
    "        x = F.elu(self.conv1(x, ei))\n",
    "        x = F.elu(self.conv2(x, ei))                      \n",
    "        x, (ei3, alpha3) = self.conv3(x, ei, return_attention_weights=True) \n",
    "\n",
    "        # build dense Laplacian surrogate from layer‑3 attention\n",
    "        adj = self._dense_adj(ei3, alpha3, batch)\n",
    "        mask = torch.ones(adj.size(0), dtype=torch.bool, device=adj.device)\n",
    "\n",
    "        S1, x1, adj1, mod1, ort1, clu1 = self.pool1(x, adj, mask)\n",
    "        S2, x2, adj2, mod2, ort2, clu2 = self.pool2(x1, adj1)\n",
    "\n",
    "        # read‑out\n",
    "        x2 = self.proj(x2).squeeze(-1)\n",
    "        logits = self.classifier(x2)\n",
    "\n",
    "        pool_reg = (mod1 + clu1 + 0.1 * ort1) + (mod2 + clu2 + 0.1 * ort2)\n",
    "        return logits, pool_reg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6bc6f624-5d77-4604-a8bd-9fe5bd19c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(loader, model, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out, pool_reg = model(data)\n",
    "        loss = F.cross_entropy(out, data.y) + pool_reg.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def test_epoch(loader, model, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for data in tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        out, pool_reg = model(data)\n",
    "        loss = F.cross_entropy(out, data.y) + pool_reg.mean()\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == data.y).sum().item()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e6e7847a-eec2-4cca-b58a-0c9a6cfd3412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 1.2849,  ..., 3.9047, 1.8204, 0.6522],\n",
      "       dtype=torch.float64)\n",
      "tensor([[    3,     0,  6682,  ..., 13358, 20040, 20037],\n",
      "        [    0,     3,  6679,  ..., 13361, 20037, 20040],\n",
      "        [   12,     0,  6691,  ..., 13358, 20049, 20037],\n",
      "        ...,\n",
      "        [ 6646,  6678, 13325,  ..., 20036, 26683, 26715],\n",
      "        [ 6678,  6653, 13357,  ..., 20011, 26715, 26690],\n",
      "        [ 6653,  6678, 13332,  ..., 20036, 26690, 26715]])\n",
      "tensor([0, 0, 0,  ..., 3, 3, 3])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m optimizer = torch.optim.Adam(model.parameters(), lr=\u001b[32m0.005\u001b[39m, weight_decay=\u001b[32m5e-4\u001b[39m)\n\u001b[32m      3\u001b[39m device = \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(loader, model, optimizer, device)\u001b[39m\n\u001b[32m      5\u001b[39m data = data.to(device)\n\u001b[32m      6\u001b[39m optimizer.zero_grad()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m out, pool_reg = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m loss = F.cross_entropy(out, data.y) + pool_reg.mean()\n\u001b[32m      9\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/cpsc452/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/cpsc452/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mGAT.forward\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(ei)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(batch)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m x = F.elu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mei\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     40\u001b[39m x = F.elu(\u001b[38;5;28mself\u001b[39m.conv2(x, ei))                      \n\u001b[32m     41\u001b[39m x, (ei3, alpha3) = \u001b[38;5;28mself\u001b[39m.conv3(x, ei, return_attention_weights=\u001b[38;5;28;01mTrue\u001b[39;00m) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/cpsc452/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/cpsc452/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/cpsc452/lib/python3.13/site-packages/torch_geometric/nn/conv/gatv2_conv.py:281\u001b[39m, in \u001b[36mGATv2Conv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[39m\n\u001b[32m    279\u001b[39m x_r: OptTensor = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m x.dim() == \u001b[32m2\u001b[39m\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    284\u001b[39m         res = \u001b[38;5;28mself\u001b[39m.res(x)\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = GAT()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "device = 'cpu'\n",
    "\n",
    "loss = train_epoch(loader, model, optimizer, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
