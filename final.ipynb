{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a14b620c-9456-41b4-9e88-f11d8090f35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-scatter in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: torch-geometric in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from torch-geometric) (3.11.16)\n",
      "Requirement already satisfied: fsspec in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from torch-geometric) (2024.12.0)\n",
      "Requirement already satisfied: jinja2 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from torch-geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from aiohttp->torch-geometric) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from aiohttp->torch-geometric) (1.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from requests->torch-geometric) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from requests->torch-geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from requests->torch-geometric) (2025.1.31)\n",
      "Requirement already satisfied: plotnine in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (0.14.5)\n",
      "Requirement already satisfied: matplotlib>=3.8.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from plotnine) (3.10.1)\n",
      "Requirement already satisfied: pandas>=2.2.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from plotnine) (2.2.3)\n",
      "Requirement already satisfied: mizani~=0.13.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from plotnine) (0.13.5)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from plotnine) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from plotnine) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.14.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from plotnine) (0.14.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from pandas>=2.2.0->plotnine) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from pandas>=2.2.0->plotnine) (2025.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from statsmodels>=0.14.0->plotnine) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/rhou/anaconda3/envs/cpsc552/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->plotnine) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter\n",
    "!pip install torch-geometric\n",
    "!pip install plotnine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e8cfe-3031-4e8b-9f4a-0a8eac7ea6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, InMemoryDataset, Dataset\n",
    "from torch_geometric.nn import GATConv, GATv2Conv, DMoNPooling\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from plotnine import ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "308170d3-8192-4cd2-a7dc-16e32ff60105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "metacells = pd.read_csv(\"./oligo-SCZ-metacellExpr.csv\", index_col=0)\n",
    "metadata = pd.read_csv(\"./oligo-SCZ-meta.csv\", index_col=0)\n",
    "tom = pd.read_csv(\"./oligo-SCZ-tom.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3688d75-b0e4-4f0c-afc2-9c0976efa9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oligo#CON1_2             Control\n",
       "Oligo#CON10_5            Control\n",
       "Oligo#CON10_55           Control\n",
       "Oligo#CON10_105          Control\n",
       "Oligo#CON11_41           Control\n",
       "                       ...      \n",
       "Oligo#SZ15_10      Schizophrenia\n",
       "Oligo#SZ16_47      Schizophrenia\n",
       "Oligo#SZ16_97      Schizophrenia\n",
       "Oligo#SZ16_147     Schizophrenia\n",
       "Oligo#SZ18_1       Schizophrenia\n",
       "Name: disorder, Length: 100, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.iloc[1:5000:50,:][\"disorder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fcf3c1a-3706-4ec2-bd91-c101d2f22c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 1.28492008, ..., 3.60950374, 1.82917698,\n",
       "       0.83603014])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metacells.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ce2079-8a74-4111-a1c1-052721ff72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "TOM_THRESHOLD = 0.025  # value below which we zero out the similarity that will be used as attention priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8734aa97-8f22-470f-82d9-b36b4a8dc813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6679/6679 [05:47<00:00, 19.22it/s] \n"
     ]
    }
   ],
   "source": [
    "# create graph dataset\n",
    "edges = []\n",
    "for i in tqdm(range(len(tom.columns))):\n",
    "    for j in range(i):\n",
    "        if tom.iloc[i,j] > TOM_THRESHOLD:\n",
    "            edges.extend([[i,j],[j,i]])\n",
    "edges = torch.tensor(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d0beec-7d02-4117-96bd-57e339a06a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metacellsReduced = metacells.iloc[:,0:5000:50]\n",
    "metadataReduced = metadata.iloc[0:5000:50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3df5d3d7-e95b-4f52-b72d-8a094c40193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOT USING CURRENTLY\n",
    "\n",
    "# class GeneGraphDataset(InMemoryDataset):\n",
    "#     def __init__(self, root, edge_index, expr_mat, meta, transform=None, pre_transform=None):\n",
    "#         self.edge_index = edge_index\n",
    "#         self.num_graphs = expr_mat.shape[1]\n",
    "#         self.expr_mat = expr_mat\n",
    "#         self.num_classes = 2\n",
    "#         self.y = meta[\"disorder\"]\n",
    "#         super().__init__(root, transform, pre_transform)\n",
    "#         self.load(\"./graphData/processed/combined.pt\")\n",
    "\n",
    "#     @property\n",
    "#     def raw_file_names(self):\n",
    "#         pass\n",
    "\n",
    "#     @property\n",
    "#     def processed_file_names(self):\n",
    "#         return [f\"./graphData/processed/{self.expr_mat.columns[i]}-graph.pt\" for i in range(self.num_graphs)]\n",
    "\n",
    "#     def process(self):\n",
    "#         data_list = []\n",
    "#         for i in tqdm(range(self.num_graphs)):\n",
    "#             node_features = torch.tensor(self.expr_mat.iloc[:,i].values)\n",
    "#             data = Data(x=node_features, edge_index=self.edge_index)\n",
    "#             data_list.append(data)\n",
    "#             torch.save(data, f\"./graphData/processed/{self.expr_mat.columns[i]}-graph.pt\")\n",
    "\n",
    "#         data, slices = self.collate(data_list)\n",
    "#         torch.save((data, slices), f\"./graphData/processed/combined.pt\")\n",
    "\n",
    "#     def get(self, idx=None, sample=None):\n",
    "#         if idx is None:\n",
    "#             data = torch.load(f\"./graphData/processed/{sample}-graph.pt\", weights_only=False)\n",
    "#         else:\n",
    "#             data = torch.load(f\"./graphData/processed/{self.expr_mat.columns[idx]}-graph.pt\", weights_only=False)\n",
    "#         return data\n",
    "\n",
    "\n",
    "# dataset = GeneGraphDataset(root='./graphData', edge_index=edges.t().contiguous(), expr_mat=metacellsReduced, meta=metadataReduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c0507-60d4-4df5-9784-e9ff17702db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/_9p7v45s62567_bm_c4m9l7c0000gn/T/ipykernel_36227/2359340812.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "metadataReduced.loc[:,\"disorder_encoded\"] = le.fit_transform(metadataReduced[\"disorder\"])\n",
    "\n",
    "dataset = []\n",
    "nGenes = metacellsReduced.shape[0]\n",
    "edgesT = edges.t().contiguous()\n",
    "num_samples = min(100, metacellsReduced.shape[1], metadataReduced.shape[0])  # Ensure we don't exceed available data\n",
    "for i in range(num_samples):\n",
    "    dataset.append(\n",
    "    Data(\n",
    "        x=torch.tensor(metacellsReduced.iloc[:, i].values, dtype=torch.float32).reshape((nGenes, 1)),\n",
    "        edge_index=edgesT,\n",
    "        y=torch.tensor(metadataReduced[\"disorder_encoded\"].iloc[i], dtype=torch.long)\n",
    "    )\n",
    ")\n",
    "random.shuffle(dataset)\n",
    "loader = DataLoader(dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ba992-e904-4591-a877-6666d2c7482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(metacells, metadata, edges, idx_train, idx_test):\n",
    "    train = []\n",
    "    test = []\n",
    "    nGenes = metacells.shape[0]\n",
    "    edgesT = edges.t().contiguous()\n",
    "    for i in idx_train:\n",
    "        train.append(Data(\n",
    "            x=torch.tensor(metacells.iloc[:,i].values, dtype=torch.float32).reshape((nGenes,1)),\n",
    "            edge_index=edgesT,\n",
    "            y=torch.tensor(metadata[\"disorder_encoded\"].iloc[i], dtype=torch.long)\n",
    "        ))\n",
    "    for i in idx_test:\n",
    "        test.append(Data(\n",
    "            x=torch.tensor(metacells.iloc[:,i].values, dtype=torch.float32).reshape((nGenes,1)),\n",
    "            edge_index=edgesT,\n",
    "            y=torch.tensor(metadata[\"disorder_encoded\"].iloc[i], dtype=torch.long)\n",
    "        )) \n",
    "    random.shuffle(train)\n",
    "    random.shuffle(test)\n",
    "    return DataLoader(train, batch_size=4), DataLoader(test, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647c3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.loc[:,\"disorder_encoded\"] = le.fit_transform(metadata[\"disorder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97e58a07-9578-4459-bfdf-7f66396e9808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.num_features = 1\n",
    "        self.hidden_layers = 1\n",
    "        self.k = 128\n",
    "        self.in_heads = 8\n",
    "        self.mid_heads = 2\n",
    "        self.out_heads = 1\n",
    "\n",
    "        self.conv1 = GATv2Conv(self.num_features, self.hidden_layers, heads=self.in_heads, dropout=0.4)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(self.hidden_layers * self.in_heads)\n",
    "        self.conv2 = GATv2Conv(self.hidden_layers*self.in_heads, self.hidden_layers, heads=self.mid_heads, dropout=0.4)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(self.hidden_layers * self.mid_heads)\n",
    "        self.conv3 = GATv2Conv(self.hidden_layers*self.mid_heads, self.hidden_layers, heads=self.out_heads, dropout=0.4)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(self.hidden_layers)\n",
    "\n",
    "        self.pool = DMoNPooling([self.hidden_layers, self.hidden_layers], k=self.k, dropout=0.4)\n",
    "\n",
    "        self.proj = torch.nn.Linear(self.hidden_layers, 1)\n",
    "\n",
    "        self.classifier = torch.nn.Linear(self.k, 2)\n",
    "\n",
    "    def _dense_adj(self, edge_index, alpha, batch):\n",
    "        alpha = alpha.mean(dim=1)\n",
    "        adj = to_dense_adj(edge_index, batch=batch, edge_attr=alpha)  # shape: [B, N, N]\n",
    "        deg = adj.sum(-1).clamp(min=1e-12)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm_adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)\n",
    "        return norm_adj\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, ei, batch = data.x, data.edge_index, data.batch\n",
    "        # print(x)\n",
    "        # print(ei)\n",
    "        # print(batch)\n",
    "\n",
    "        x = F.elu(self.conv1(x, ei))\n",
    "        x = F.elu(self.conv2(x, ei))                      \n",
    "        x, (ei3, alpha3) = self.conv3(x, ei, return_attention_weights=True) \n",
    "        x = F.elu(self.bn3(x))\n",
    "\n",
    "        # convert to dense batch and corresponding mask\n",
    "        x_dense, mask = to_dense_batch(x, batch)\n",
    "\n",
    "        # build dense adjacency matrix\n",
    "        alpha = alpha3.mean(dim=1)\n",
    "        adj_dense = to_dense_adj(ei3, batch=batch, edge_attr=alpha)\n",
    "        deg = adj_dense.sum(-1).clamp(min=1e-12)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        adj_dense = deg_inv_sqrt.unsqueeze(-1) * adj_dense * deg_inv_sqrt.unsqueeze(-2)\n",
    "\n",
    "        S, x, adj, mod, ort, clu = self.pool(x_dense, adj_dense, mask)\n",
    "\n",
    "        # read‑out\n",
    "        x = self.proj(x).squeeze(-1)\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        pool_reg = mod + clu + 0.1 * ort\n",
    "        return logits, pool_reg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6f624-5d77-4604-a8bd-9fe5bd19c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(loader, model, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    iter_loss = []\n",
    "    train_iter = tqdm(loader)\n",
    "    for data in train_iter:\n",
    "        data = data.to(device)\n",
    "        # data.y = data.y.long()\n",
    "        optimizer.zero_grad()\n",
    "        out, pool_reg = model(data)\n",
    "        loss = F.cross_entropy(out, data.y.squeeze()) + pool_reg.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_iter.set_description(f\"(loss {loss.item()})\")\n",
    "        iter_loss.append(loss.item())\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset), iter_loss\n",
    "\n",
    "def test_epoch(loader, model, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    correct_readouts = []\n",
    "    test_iter = tqdm(loader)\n",
    "    for data in test_iter:\n",
    "        data = data.to(device)\n",
    "        # data.y = data.y.long()\n",
    "        out, pool_reg = model(data)\n",
    "        loss = F.cross_entropy(out, data.y.squeeze()) + pool_reg.mean()\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == data.y).sum().item()\n",
    "        correct_readout = [\"SCZ\" if item == 1 else \"CON\" for item in data.y]\n",
    "        for i, item in enumerate(pred == data.y):\n",
    "            correct_readout[i] += \"(√)\" if item else \"(x)\"\n",
    "        correct_readouts.extend(correct_readout)\n",
    "        test_iter.set_description(f\"(loss {loss.item()}; {(pred == data.y).sum().item()}/{loader.batch_size} [{\" \".join(correct_readout)}])\")\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset), correct / len(loader.dataset), correct_readouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e7847a-eec2-4cca-b58a-0c9a6cfd3412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:45<18:21, 45.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/25: Loss: 0.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [01:25<16:10, 42.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2/25: Loss: 0.4776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [02:11<16:05, 43.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3/25: Loss: 0.4883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [02:50<14:39, 41.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4/25: Loss: 0.4961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [03:37<14:39, 43.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5/25: Loss: 0.3855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [04:16<13:18, 42.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6/25: Loss: 0.5240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [04:59<12:43, 42.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7/25: Loss: 0.3922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [05:40<11:52, 41.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8/25: Loss: 0.6588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [06:20<11:02, 41.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9/25: Loss: 0.3633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [07:02<10:23, 41.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10/25: Loss: 0.3893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [07:46<09:53, 42.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11/25: Loss: 0.4746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [08:15<08:17, 38.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12/25: Loss: 0.5020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [08:43<07:00, 35.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13/25: Loss: 0.3590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [09:08<05:54, 32.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14/25: Loss: 0.4852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [09:32<04:57, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15/25: Loss: 0.3858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [09:57<04:13, 28.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16/25: Loss: 0.5541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [10:20<03:33, 26.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17/25: Loss: 0.6258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [10:44<03:00, 25.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/25: Loss: 0.7096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [11:08<02:31, 25.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 19/25: Loss: 0.4449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [11:31<02:02, 24.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20/25: Loss: 3.3261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [11:55<01:38, 24.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 21/25: Loss: 5.1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [12:17<01:11, 23.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 22/25: Loss: 4.6731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [12:41<00:47, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 23/25: Loss: 5.8178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [13:06<00:24, 24.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 24/25: Loss: 5.6066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [13:29<00:00, 32.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 25/25: Loss: 5.6775\n",
      "Train Loss: {epoch_loss:.4f}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [06:29<00:00, 15.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.1116, Test Accuracy: 0.2200\n"
     ]
    }
   ],
   "source": [
    "model = GAT()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "device = 'cpu'\n",
    "\n",
    "train_loader, test_loader = train_test(metacells, metadata, edges, list(range(0, 5000, 50)), list(range(25, 5025, 50)))\n",
    "\n",
    "loss, loss_arr = train_epoch(train_loader, model, optimizer, device)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624d042-6e1e-4eed-a271-89de5a5e6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss, correct, correct_readouts = test_epoch(test_loader, model, device)\n",
    "print(\"Test Loss: \", total_loss)\n",
    "print(\"Test Accuracy: \", correct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
